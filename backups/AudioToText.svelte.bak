<!--
  This is the main component for audio recording and transcription.
  It handles recording, transcription, clipboard operations, and UI feedback.
-->
<script>
	import { geminiService } from '$lib/services/geminiService';
	import { promptStyle, theme } from '$lib/index.js';
import { AudioStates } from '$lib/services/audio/audioStates';
	import { onMount, onDestroy } from 'svelte';
import { fade, fly } from 'svelte/transition';
import { quintOut } from 'svelte/easing';
	import AudioVisualizer from './AudioVisualizer.svelte';
	import RecordButtonWithTimer from './RecordButtonWithTimer.svelte';
	import TranscriptDisplay from './TranscriptDisplay.svelte';
	import PermissionError from './PermissionError.svelte';
	import { ANIMATION, CTA_PHRASES, ATTRIBUTION, getRandomFromArray } from '$lib/constants';
	import { Confetti } from '$lib/components/ui';
	
	// State for confetti animation
	let showConfetti = false;
	let confettiTarget = '.ghost-icon-wrapper'; // Target the ghost icon so confetti explodes from behind it
	let confettiColors = ANIMATION.CONFETTI.COLORS; // Default colors
	
	// Function to get theme-specific confetti colors
	function getThemeConfettiColors() {
		// Get current theme from the store
		let currentTheme;
		const unsubscribe = theme.subscribe(value => {
			currentTheme = value;
		});
		unsubscribe();
		
		// Use theme-specific colors if available
		if (currentTheme && ANIMATION.CONFETTI.THEME_COLORS[currentTheme]) {
			return ANIMATION.CONFETTI.THEME_COLORS[currentTheme];
		}
		
		// Fallback to default colors
		return ANIMATION.CONFETTI.COLORS;
	}
	
	import {
		initializeServices,
		audioService,
		transcriptionService,
		pwaService,
		// Stores
		isRecording,
		isTranscribing,
		transcriptionProgress,
		transcriptionText, // Kept for display and general debug, but not for completion trigger
		transcriptionState, // Added parent store to update text directly
		recordingDuration,
		errorMessage,
		uiState,
		audioState,
		hasPermissionError,
		// Actions
		audioActions,
		transcriptionActions,
		uiActions
	} from '$lib/services';
	import { get } from 'svelte/store';

	// Helper variable to check if we're in a browser environment
	const browser = typeof window !== 'undefined';

	// Service instances
	let services;
	let unsubscribers = [];

	// DOM element references
	let progressContainerElement;

	// Local component state
	let showCopyTooltip = false;
	let screenReaderStatus = ''; // For ARIA announcements
	let isPremiumUser = false; // Change this to true to enable premium features

	// These will be set from the parent component
	export let isModelPreloaded = false;
	export let onPreloadRequest = null;

	// Ghost component reference
	export let ghostComponent = null;
	
	// Parent ContentContainer reference
	export let parentContainer = null;

	// Prompt style subscription
	let currentPromptStyle;
	const unsubscribePromptStyle = promptStyle.subscribe((value) => {
		currentPromptStyle = value;
	});

	// Export recording state and functions for external components
	export const recording = isRecording; // Export the isRecording store
	export { stopRecording, startRecording };
	
	// Store the last successful audio blob for re-rolling
	let lastAudioBlob = null;
	
	// Handle re-roll request from transcript display
	async function handleReroll() {
		try {
			if (!lastAudioBlob) {
				uiActions.setErrorMessage('No audio data available for re-roll');
				return;
			}
			
			// Set UI state to indicate re-rolling
			transcriptionActions.startTranscribing();
			
			// Clear any previous error messages
			uiActions.clearErrorMessage();
			
			// Set initial transcription text to indicate re-rolling
			// Don't set to null as it causes the component to unmount
			// Instead, create a centered, prettier re-rolling message with HTML formatting
			console.log('[DEBUG] Setting transcript to re-rolling message');
			// Simple re-rolling message as plain text
const reRollingMessage = "‚ú® Re-rolling lyrics... ‚è≥";
			
			// Update state with HTML-formatted message
			transcriptionState.update(current => ({
				...current,
				text: reRollingMessage,
				rerolling: true // Flag to trigger animations
			}));
			
			// Trigger the height animation by forcing a layout reflow
			// This will make the bloopy animation look nicer
			setTimeout(() => {
				const el = document.querySelector('.transcript-container');
				if (el) {
					void el.offsetHeight; // Force reflow
					console.log('[DEBUG] Forcing reflow for animation');
				}
			}, 10);
			
			// Subtle pulse ghost icon when re-rolling
			if (ghostComponent && typeof ghostComponent.pulse === 'function') {
				ghostComponent.pulse();
			}
			
			// If ghost has "thinking" animation, use it
			if (ghostComponent && typeof ghostComponent.startThinking === 'function') {
				ghostComponent.startThinking();
			}
			
			// Re-transcribe the audio with same prompt style (possibly different interpretation/output)
			const newTranscript = await transcriptionService.transcribeAudio(lastAudioBlob);
			
			// Log the result to ensure we're getting a response
			console.log('[DEBUG] Re-rolled transcript received:', newTranscript);
			
			// Reset the rerolling state for animations
			transcriptionState.update(current => ({
				...current,
				rerolling: false
			}));
			
			// CRITICAL: Ensure the transcript is updated for re-rolls
			// Use direct state update instead of event emission
			if (newTranscript) {
				console.log('[DEBUG] Updating transcript text after re-roll, text length:', newTranscript?.length);
				// Force direct update via state
				transcriptionState.update(current => ({
					...current,
					text: newTranscript
				}));
				
				// Also call completion handler directly
				handleTranscriptCompletion(newTranscript);
			} else {
				console.warn('[DEBUG] Unable to update - missing transcript');
			}
			
			// Auto-scroll disabled to keep existing content in view
			
			// Stop thinking animation
			if (ghostComponent && typeof ghostComponent.stopThinking === 'function') {
				ghostComponent.stopThinking();
			}
		} catch (err) {
			console.error('‚ùå Error re-rolling transcript:', err);
			uiActions.setErrorMessage(`Re-roll error: ${err.message || 'Unknown error'}`);
			
			// Reset transcription state and animation flags
			transcriptionActions.updateProgress(0);
			transcriptionActions.completeTranscription($transcriptionText);
			transcriptionState.update(current => ({
				...current,
				rerolling: false
			}));
			
			// Stop thinking animation if it's still running
			if (ghostComponent && typeof ghostComponent.stopThinking === 'function') {
				ghostComponent.stopThinking();
			}
		}
	}

	// PWA Installation State Tracking - now using pwaService

	// Export PWA installation state functions through the service
	const shouldShowPWAPrompt = () => pwaService.shouldShowPwaPrompt();
	const recordPWAPromptShown = () => pwaService.recordPromptShown();
	const markPWAAsInstalled = () => pwaService.markAsInstalled();
	const isRunningAsPWA = () => pwaService.checkIfRunningAsPwa();

	export { shouldShowPWAPrompt, recordPWAPromptShown, markPWAAsInstalled, isRunningAsPWA };

	/**
	 * Increment transcription count and dispatch an event.
	 * Delegates to PWA service for actual storage.
	 */
	function incrementTranscriptionCount() {
		if (!browser) return;

		try {
			const newCount = pwaService.incrementTranscriptionCount();

			// Dispatch event to parent
			dispatchEvent(new CustomEvent('transcriptionCompleted', { detail: { count: newCount } }));
		} catch (error) {
			console.error('Error incrementing transcription count:', error);
		}
	}
	// End of PWA tracking

	// Function to preload the speech model before recording starts
	function preloadSpeechModel() {
		if (onPreloadRequest) {
			onPreloadRequest();
		}
	}

	async function startRecording() {
		// Don't start if we're already recording
		if ($isRecording) return;

		// Try to preload the speech model if not already done
		preloadSpeechModel();

		// Reset UI state
		uiActions.clearErrorMessage();

		// We don't need to set up recording timer manually anymore
		// The store takes care of it

		// Removed auto-scroll when recording starts to keep the visualizer visible

		try {
			// Subtle pulse ghost icon when starting recording
			if (ghostComponent && typeof ghostComponent.pulse === 'function') {
				ghostComponent.pulse();
			}

			// Start recording using the AudioService
			await audioService.startRecording();

			// State is tracked through stores now
		} catch (err) {
			console.error('‚ùå Error in startRecording:', err);
			uiActions.setErrorMessage(`Recording error: ${err.message || 'Unknown error'}`);
		}
	}

	/**
	 * Stops the current recording and initiates the transcription process
	 * @returns {Promise<void>}
	 */
	async function stopRecording() {
		// Timing metadata for debugging
		const timeMarkers = {
			start: Date.now(),
			audioBlob: 0,
			transcriptionStart: 0,
			transcriptionEnd: 0,
			uiUpdate: 0
		};
		
		try {
			// Verify that we're actually recording
			if (!$isRecording) {
				console.log('[DEBUG] stopRecording called but not recording');
				return;
			}

			// Update ghost UI for user feedback
			if (ghostComponent) {
				ghostComponent.forceWobble?.();
				ghostComponent.startThinking?.();
			}

			// Get audio blob from recording service
			timeMarkers.audioBlob = Date.now();
			console.log(`[DEBUG] Stopping recording, elapsed: ${timeMarkers.audioBlob - timeMarkers.start}ms`);
			const audioBlob = await audioService.stopRecording();

			// Validate audio blob
			if (!audioBlob || audioBlob.size === 0) {
				throw new Error('No audio data received');
			}
			
			console.log(`[DEBUG] Audio blob received: ${audioBlob.size} bytes, type: ${audioBlob.type}`);
			lastAudioBlob = audioBlob; // Store for re-roll feature

			// Begin transcription process
			timeMarkers.transcriptionStart = Date.now();
			console.log(`[DEBUG] Starting transcription, elapsed since stop: ${timeMarkers.transcriptionStart - timeMarkers.audioBlob}ms`);
			
			try {
				// Direct transcription call with minimal intermediate layers
				const transcriptText = await transcriptionService.transcribeAudio(audioBlob);
				timeMarkers.transcriptionEnd = Date.now();
				
				// Validate transcription result
				if (!transcriptText || transcriptText.trim() === '') {
					throw new Error('Empty transcription result');
				}
				
				console.log(`[DEBUG] Transcription successful in ${timeMarkers.transcriptionEnd - timeMarkers.transcriptionStart}ms: "${transcriptText.substring(0, 50)}..."`);
				
				// Synchronized UI update with clear order of operations
				await updateUIWithTranscription(transcriptText);
				timeMarkers.uiUpdate = Date.now();
				
				// Performance logging for debugging
				console.log('[DEBUG] Performance metrics:', {
					total: timeMarkers.uiUpdate - timeMarkers.start,
					audioProcessing: timeMarkers.audioBlob - timeMarkers.start,
					transcription: timeMarkers.transcriptionEnd - timeMarkers.transcriptionStart,
					uiUpdate: timeMarkers.uiUpdate - timeMarkers.transcriptionEnd
				});
				
			} catch (transcribeError) {
				console.error('[ERROR] Transcription failed:', transcribeError);
				
				// Reset UI state on error
				ghostComponent?.stopThinking?.();
				audioActions.updateState(AudioStates.IDLE);
				
				// Show user-friendly error message
				uiActions.setErrorMessage(`Transcription error: ${transcribeError.message}`);
			}
		} catch (err) {
			console.error('[ERROR] Recording process failed:', err);
			uiActions.setErrorMessage(`Recording error: ${err.message}`);
			
			// Reset UI state
			if (ghostComponent?.stopThinking) {
				ghostComponent.stopThinking();
			}
			audioActions.updateState(AudioStates.IDLE);
		}
	}

	/**
	 * Updates UI with transcription text in a synchronized way
	 * @param {string} transcriptText - The transcription text
	 * @returns {Promise<void>}
	 */
	async function updateUIWithTranscription(transcriptText) {
		// Step 1: Update the store state directly
		transcriptionState.update(current => ({
			...current,
			inProgress: false,
			progress: 100,
			text: transcriptText
		}));
		
		// Brief delay to allow store updates to propagate
		await new Promise(resolve => setTimeout(resolve, 10));
		
		// Step 2: Update UI components via dedicated handler
		handleTranscriptCompletion(transcriptText);
		
		// Step 3: Ensure recording state is reset
		if ($isRecording) {
			audioActions.updateState(AudioStates.IDLE);
		}
		
		// Step 4: Update ghost animation
		if (ghostComponent?.stopThinking) {
			ghostComponent.stopThinking();
		}
		
		// Step 5: Final verification - force update if needed
		const currentText = get(transcriptionText);
		if (currentText !== transcriptText) {
			console.log('[DEBUG] Safety update - text not propagated correctly');
			transcriptionActions.completeTranscription(transcriptText);
		}
	}

				// Auto-scroll disabled to keep visualizer and controls in view

				// Increment the transcription count for PWA prompt
				if (browser && 'requestIdleCallback' in window) {
					window.requestIdleCallback(() => incrementTranscriptionCount());
				} else {
					setTimeout(incrementTranscriptionCount, 0);
				}
			} else {
				// If no audio data, revert UI state
				console.log('[DEBUG] AudioBlob was null or size was 0. No transcription attempted.');
				transcriptionActions.updateProgress(0);
				uiActions.setErrorMessage('No audio recorded. Please try again.');
			}
		} catch (err) {
			console.error('‚ùå Error in stopRecording:', err);
			uiActions.setErrorMessage(`Error processing recording: ${err.message || 'Unknown error'}`);
		}
	}

	function toggleRecording() {
		try {
			// Prioritize the store state for more consistent behavior
			const currentlyRecording = get(isRecording);

			if (currentlyRecording) {
				// Haptic feedback for stop - single pulse
				if (services && services.hapticService) {
					services.hapticService.stopRecording();
				}

				stopRecording();
				// Screen reader announcement
				uiActions.setScreenReaderMessage('Recording stopped.');
			} else {
				// Haptic feedback for start - double pulse
				if (services && services.hapticService) {
					services.hapticService.startRecording();
				}

				// When using "New Recording" button, rotate to next phrase immediately
				if ($transcriptionText) {
					console.log('üßπ Clearing transcript for new recording');

					// Pick a random CTA phrase that's not the current one
					let newIndex;
					do {
						newIndex = Math.floor(Math.random() * (CTA_PHRASES.length - 1)) + 1; // Skip first one (Start Recording)
					} while (newIndex === currentCtaIndex);

					currentCtaIndex = newIndex;
					currentCta = CTA_PHRASES[currentCtaIndex];
					console.log(`üî• Rotating to: "${currentCta}"`);

					// Then clear transcript
					transcriptionActions.completeTranscription('');
				}

				startRecording();
				// Screen reader announcement
				uiActions.setScreenReaderMessage('Recording started. Speak now.');
			}
		} catch (err) {
			console.error('Recording operation failed:', err);

			// Show error message using existing toast system
			uiActions.setErrorMessage(`Recording error: ${err.message || 'Unknown error'}`);

			// Haptic feedback for error - with null check
			if (services && services.hapticService) {
				services.hapticService.error();
			}

			// Update screen reader status
			uiActions.setScreenReaderMessage('Recording failed. Please try again.');
		}
	}

	// Function to calculate responsive font size based on transcript length, word count, and device
	function getResponsiveFontSize(text) {
		if (!text) return 'text-base'; // Default size

		// Get viewport width for more responsive sizing
		let viewportWidth = 0;
		if (typeof window !== 'undefined') {
			viewportWidth = window.innerWidth;
		}

		// Smaller base sizes for mobile
		const isMobile = viewportWidth > 0 && viewportWidth < 640;
		const isDesktop = viewportWidth >= 1024;

		// Calculate both character length and word count
		const charLength = text.length;
		const wordCount = text.trim().split(/\s+/).length;
		
		// Typography best practices suggest that readability is impacted by both 
		// total length and average word length
		const avgWordLength = charLength / (wordCount || 1); // Avoid division by zero
		
		console.log(`Dynamic sizing: ${wordCount} words, ${charLength} chars, ${avgWordLength.toFixed(1)} avg length`);
		
		// Extremely short text (5 words or less): Use larger font, especially on desktop
		if (wordCount <= 5) {
			const size = isMobile 
				? 'text-xl sm:text-2xl md:text-3xl' 
				: isDesktop 
					? 'text-2xl md:text-3xl lg:text-4xl' 
					: 'text-2xl md:text-3xl';
			console.log(`Using size for ‚â§5 words: ${size}`);
			return size;
		}
		
		// Very short text: 6-10 words or under 50 chars
		if (wordCount < 10 || charLength < 50) {
			const size = isMobile ? 'text-lg sm:text-xl md:text-2xl' : 'text-xl md:text-2xl';
			console.log(`Using size for 6-10 words: ${size}`);
			return size;
		}
		
		// Short text: 11-25 words or under 150 chars with normal word length
		if ((wordCount < 25 || charLength < 150) && avgWordLength < 8) {
			const size = isMobile ? 'text-base sm:text-lg md:text-xl' : 'text-lg md:text-xl';
			console.log(`Using size for 11-25 words: ${size}`);
			return size;
		}
		
		// Medium text: 26-50 words or under 300 chars
		if (wordCount < 50 || charLength < 300) {
			const size = isMobile ? 'text-sm sm:text-base md:text-lg' : 'text-base md:text-lg';
			console.log(`Using size for 26-50 words: ${size}`);
			return size;
		}
		
		// Medium-long text: 51-100 words or under 500 chars
		if (wordCount < 100 || charLength < 500) {
			const size = isMobile ? 'text-xs sm:text-sm md:text-base' : 'text-sm md:text-base';
			console.log(`Using size for 51-100 words: ${size}`);
			return size;
		}
		
		// Long text: Over 100 words or 500+ chars
		// Use smaller text for better readability on longer content
		const size = isMobile ? 'text-xs sm:text-sm' : 'text-sm md:text-base';
		console.log(`Using size for >100 words: ${size}`);
		return size;
	}

	// Reactive font size based on transcript length
	$: responsiveFontSize = getResponsiveFontSize($transcriptionText);

	// CTA rotation
	let currentCtaIndex = 0;
	let currentCta = CTA_PHRASES[currentCtaIndex];

	// Button label computation - fixed to show CTA phrases
	$: buttonLabel = $isRecording ? 'Stop Recording' : $transcriptionText ? currentCta : currentCta;

	// Handler for transcript component events
	function handleTranscriptEvent(event) {
		const { type, detail } = event;

		if (type === 'copy') {
			// Use the transcript text from the detail property instead of calling a method on event.target
			const transcriptText = detail?.text || $transcriptionText;
			transcriptionService.copyToClipboard(transcriptText);
		} else if (type === 'share') {
			const transcriptText = detail?.text || $transcriptionText;
			transcriptionService.shareTranscript(transcriptText);
		} else if (type === 'focus') {
			uiActions.setScreenReaderMessage(detail.message);
		}
	}

	// State changes for transcript completion
	function handleTranscriptCompletion(textToProcess) { // <-- Accept text as a parameter
		console.log('[DEBUG] handleTranscriptCompletion() called with textToProcess:', textToProcess);

		// Force update UI state directly to ensure text is displayed
		// This is critical as a safety measure for transcript display
		if (textToProcess && textToProcess.trim() !== '') {
			console.log('[DEBUG] Directly updating transcription state in handleTranscriptCompletion');
			transcriptionState.update(current => ({
				...current,
				inProgress: false,
				progress: 100,
				text: textToProcess
			}));
		}

		// Only attempt to use ghost component if it exists
		if (ghostComponent && typeof ghostComponent.reactToTranscript === 'function') {
			// React to transcript with ghost expression based on length
			ghostComponent.reactToTranscript(textToProcess?.length || 0); // Use parameter

			// Stop thinking animation
			if (typeof ghostComponent.stopThinking === 'function') {
				ghostComponent.stopThinking();
			}
		}

		// Automatically copy to clipboard when transcription finishes
		if (textToProcess) { // <-- Use the passed-in parameter
			// Show confetti celebration as a random Easter egg (1/7 chance)
			if (Math.floor(Math.random() * 7) === 0) {
				// Update confetti colors based on current theme
				confettiColors = getThemeConfettiColors();
				console.log('[DEBUG] Using theme-specific confetti colors:', confettiColors);
				showConfetti = true;
				// Reset after animation completes
				setTimeout(() => {
					showConfetti = false;
				}, ANIMATION.CONFETTI.ANIMATION_DURATION + 500);
			}
			
			// Copy to clipboard with small delay to ensure UI updates
			setTimeout(() => {
				transcriptionService.copyToClipboard(textToProcess); // <-- Use parameter
				console.log("Auto-copying transcript to clipboard");
			}, 100); // Faster copying
		} else {
			console.log('[DEBUG] Inside handleTranscriptCompletion: textToProcess is FALSY.');
		}
	}

	// Lifecycle hooks
	onMount(() => {
		// Initialize services
		services = initializeServices({ debug: false });

		// Ghost element is now handled through the component reference

		// Existing subscription to transcriptionText for general debugging (no longer calls handleTranscriptCompletion)
		const transcriptUnsub = transcriptionText.subscribe((text) => {
			console.log('[DEBUG] (Raw transcriptionText update) Text:', text, 'IsTranscribing:', $isTranscribing);
			// Re-add call to handleTranscriptCompletion to ensure it gets called
			if (text && !$isTranscribing) {
				console.log('[DEBUG] Calling handleTranscriptCompletion from transcriptionText subscription');
				handleTranscriptCompletion(text);
			}
		});

		// We no longer need the transcriptionCompletedEvent subscription 
		// The direct state updates are enough

		// Subscribe to permission denied state to show error modal
		const permissionUnsub = hasPermissionError.subscribe((denied) => {
			if (denied) {
				// Show permission error modal
				uiActions.setPermissionError(true);

				// Add sad eyes animation through the Ghost component
				if (ghostComponent) {
					// We could add a sadEyes() method to the Ghost component
					// but we'll keep it simple for now
				}
			}
		});

		// Subscribe to time limit reached event
		const audioStateUnsub = audioState.subscribe((state) => {
			if (state.timeLimit === true) {
				console.log('üî¥ Time limit reached, stopping recording automatically');
				// Auto-stop recording when time limit is reached
				if (get(isRecording)) {
					// Small timeout to let the UI update first
					setTimeout(() => {
						stopRecording();
					}, 100);
				}
			}
		});

		// Add to unsubscribe list
		unsubscribers.push(transcriptUnsub, permissionUnsub, audioStateUnsub);

		// Check if the app is running as a PWA after a short delay
		if (browser) {
			setTimeout(async () => {
				const isPwa = await pwaService.checkIfRunningAsPwa();
				if (isPwa) {
					console.log('üì± App is running as PWA');
				}
			}, 100);
		}
	});

	// Clean up subscriptions and services
	onDestroy(() => {
		// Unsubscribe from all subscriptions
		unsubscribers.forEach((unsub) => unsub());

		// Ensure audio resources are released
		audioService.cleanup();

		// Unsubscribe from prompt style
		if (unsubscribePromptStyle) unsubscribePromptStyle();
	});

	// Recording state is now handled by the Ghost component via props

	// Use reactive declarations for progress updates instead of DOM manipulation
	$: progressValue = $transcriptionProgress;
</script>

<!-- Main wrapper with proper containment to prevent layout issues -->
<div class="main-wrapper mx-auto box-border w-full">
	<!-- Shared container with proper centering for mobile -->
	<div class="mobile-centered-container flex w-full flex-col items-center justify-center">
		<!-- Recording button/progress bar section - sticky positioned for stability -->
		<div
			class="button-section relative sticky top-0 z-20 flex w-full justify-center text-center bg-transparent pb-2 pt-2 sm:pt-3 md:pt-4 sm:pb-2 md:pb-2 mt-2 sm:mt-3"
		>
			<div class="button-container flex items-center justify-center w-full" style="margin-left: auto; margin-right: auto; position: relative; left: 0; right: 0; text-align: center;">
				<RecordButtonWithTimer
					recording={$isRecording}
					transcribing={$isTranscribing}
					clipboardSuccess={$uiState.clipboardSuccess}
					lyricsCollected={$uiState.lyricsCollected}
					recordingDuration={$recordingDuration}
					progress={progressValue}
					{isPremiumUser}
					{buttonLabel}
					on:click={toggleRecording}
					on:preload={preloadSpeechModel}
				/>
			</div>
		</div>

		<!-- Dynamic content area with smooth animation and proper containment -->
		<div
			class="position-wrapper relative mb-0 mt-0 flex w-full flex-col items-center transition-all duration-300 ease-in-out"
		>
			<!-- Content container with controlled overflow -->
			<div class="content-container flex w-full flex-col items-center gap-2">
				<!-- Audio visualizer - only visible when recording -->
				<div class="visualizer-space" class:active={$isRecording}>
					{#if $isRecording}
						<div class="visualizer-container flex w-full justify-center" 
							transition:fade={{ duration: 400, delay: 100, easing: quintOut }}>
							<div class="wrapper-container flex w-full justify-center">
								<div
									class="visualizer-wrapper mx-auto w-[90%] max-w-[500px] rounded-[2rem] border-[1.5px] border-pink-100 bg-white/80 p-4 backdrop-blur-md sm:w-full"
								>
									<AudioVisualizer />
								</div>
							</div>
						</div>
					{/if}
				</div>

				<!-- Transcript output - show whenever we have non-empty transcript, regardless of recording state -->
				{#if $transcriptionText && $transcriptionText !== ''}
					<div class="transcript-container transition-all duration-500 ease-in-out" 
					     style="transform-origin: top center; min-width: 280px;" 
					     class:animate-height-bloopy={$transcriptionState.rerolling}>
						<TranscriptDisplay
							transcript={$transcriptionText || ''}
							{showCopyTooltip}
							{responsiveFontSize}
							{parentContainer}
							on:copy={handleTranscriptEvent}
							on:reroll={handleReroll}
							on:focus={handleTranscriptEvent}
						/>
					</div>
				{/if}
			</div>

			<!-- Error message -->
			{#if $errorMessage}
				<div class="error-message mt-6 text-center mx-auto max-w-md">
					{#if $errorMessage.includes('Failed to transcribe audio with Gemini')}
						<div class="bg-purple-50 border-2 border-purple-200 rounded-xl p-4 shadow-md mx-auto w-[90%]"
						     style="box-shadow: 0 4px 12px rgba(139, 92, 246, 0.15), 0 2px 4px rgba(139, 92, 246, 0.1);">
							<div class="flex items-center justify-center mb-3">
								<div class="bg-purple-100 p-2 rounded-full">
									<svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 text-purple-600" viewBox="0 0 20 20" fill="currentColor">
										<path fill-rule="evenodd" d="M18 10a8 8 0 11-16 0 8 8 0 0116 0zm-7-4a1 1 0 11-2 0 1 1 0 012 0zM9 9a1 1 0 000 2v3a1 1 0 001 1h1a1 1 0 100-2v-3a1 1 0 00-1-1H9z" clip-rule="evenodd" />
									</svg>
								</div>
							</div>
							<p class="font-semibold text-purple-800 mb-2">API Key Required</p>
							<p class="text-sm text-purple-700 mb-4 leading-relaxed">
								Please add your Gemini API key in Settings to enable transcription.
							</p>
							<a 
								href="#" 
								on:click|preventDefault={() => window.dispatchEvent(new CustomEvent('show-settings'))}
								class="inline-block px-4 py-2 text-sm font-medium text-white bg-gradient-to-r from-purple-500 to-pink-500 rounded-lg hover:from-purple-600 hover:to-pink-600 shadow-sm hover:shadow transition-all duration-200 transform hover:-translate-y-px focus:outline-none focus:ring-2 focus:ring-purple-300"
							>
								‚ú® Open Settings
							</a>
						</div>
					{:else}
						<p class="font-medium text-red-500 px-4 py-2 bg-red-50 border border-red-200 rounded-lg shadow-sm">
							{$errorMessage}
						</p>
					{/if}
				</div>
			{/if}
		</div>
	</div>
</div>

<!-- Confetti component - display centered to the transcript box when triggered -->
{#if showConfetti}
  <Confetti 
    targetSelector={confettiTarget} 
    colors={confettiColors}
    on:complete={() => showConfetti = false} 
  />
{/if}

<!-- Screen reader only status announcements -->
<div role="status" aria-live="polite" aria-atomic="true" class="sr-only">
	{#if $uiState.screenReaderMessage}
		{$uiState.screenReaderMessage}
	{/if}
</div>

<!-- Permission error modal -->
{#if $uiState.showPermissionError}
	<PermissionError on:close={() => uiActions.setPermissionError(false)} />
{/if}

<style>
	/* Main wrapper to ensure proper positioning */
.main-wrapper {
	position: relative;
	z-index: 1;
	width: 100%;
	box-sizing: border-box;
}

/* Position wrapper to create a stable layout without shifts */
.position-wrapper {
	min-height: clamp(60px, 10vh, 80px); /* Responsive min-height using clamp */
	height: auto; /* Use auto height instead of max-height to prevent scrollbar */
	display: flex;
	flex-direction: column;
	align-items: center;
	position: relative; /* Ensure proper positioning context */
	overflow: visible; /* Allow content to be visible outside the container */
	transition: all 0.3s ease-in-out; /* Smooth transition when content changes */
	contain: content; /* Use content containment instead of paint layout for better scrolling behavior */
	padding: 0 clamp(4px, 1vw, 8px); /* Responsive horizontal padding */
	margin-bottom: clamp(0px, 2vh, 16px); /* Responsive bottom margin */
}

/* Content container for transcripts and visualizers */
.content-container {
	width: 100%;
	display: flex;
	flex-direction: column;
	align-items: center;
	position: relative; /* For absolute positioned children */
}

/* Wrapper container for consistent max-width across components */
.wrapper-container {
	width: 100%;
}

/* Visualizer space that expands/contracts smoothly */
.visualizer-space {
    height: 0;
    overflow: hidden;
    transition: height 0.4s cubic-bezier(0.4, 0, 0.2, 1);
    width: 100%;
    margin-bottom: 0;
}

.visualizer-space.active {
    height: 140px; /* Adjust this value based on your visualizer's size */
    margin-bottom: 16px;
    margin-top: 16px; /* Add top margin to create space between recording button and visualizer */
}

/* Visualizer container for absolute positioning */
.visualizer-container {
	z-index: 10;
    height: 100%;
}

/* Visualizer wrapper with consistent styling */
.visualizer-wrapper {
    --shadow-color1: rgba(249, 168, 212, 0.3);
    --shadow-color2: rgba(249, 168, 212, 0.2);
    --shadow-color3: rgba(249, 168, 212, 0.15);
    box-shadow: 
        0 10px 25px -5px var(--shadow-color1), 
        0 8px 10px -6px var(--shadow-color2), 
        0 0 15px var(--shadow-color3);
}

/* Common animation for fading elements in */
.animate-fadeIn {
	animation: localFadeIn 0.8s ease-out forwards;
}

@keyframes localFadeIn {
	from {
		opacity: 0;
		transform: translateY(10px);
	}
	to {
		opacity: 1;
		transform: translateY(0);
	}
}

/* Screen reader only class */
.sr-only {
	position: absolute;
	width: 1px;
	height: 1px;
	padding: 0;
	margin: -1px;
	overflow: hidden;
	clip: rect(0, 0, 0, 0);
	white-space: nowrap;
	border-width: 0;
}

/* Bloopy height animation for the transcript container */
.animate-height-bloopy {
	animation: heightBloopy 1s cubic-bezier(0.34, 1.56, 0.64, 1) forwards;
}

@keyframes heightBloopy {
	0% { transform: scaleY(0.98); }
	50% { transform: scaleY(1.02); }
	70% { transform: scaleY(0.99); }
	100% { transform: scaleY(1); }
}

/* Loading dot animation for re-rolling indicator */
.loading-dot {
	animation: pulseFade 1.5s ease-in-out infinite;
	font-size: 1.5rem;
}

@keyframes pulseFade {
	0% { opacity: 0.3; transform: scale(0.8); }
	50% { opacity: 1; transform: scale(1.2); }
	100% { opacity: 0.3; transform: scale(0.8); }
}

/* Improved focus styles for keyboard navigation */
:focus-visible {
	outline: 2px solid #f59e0b;
	outline-offset: 2px;
}

/* Apply box-sizing to all elements for consistent layout */
* {
	box-sizing: border-box;
}

/* Mobile-centered container */
.mobile-centered-container {
	width: 100%;
	max-width: 100vw;
	margin: 0 auto;
	text-align: center;
	display: flex;
	flex-direction: column;
	align-items: center;
	justify-content: center;
	gap: 0; /* Remove gap between elements for tighter spacing */
}

/* Make the button section sticky to prevent jumping */
.button-section {
	position: sticky;
	top: 0;
	z-index: 20;
	padding-bottom: 8px; /* Add a small amount of padding */
	margin-bottom: 8px; /* Add some margin to ensure separation */
	background: transparent;
	display: flex;
	align-items: center;
	justify-content: center;
	width: 100%;
}

/* Media queries for mobile responsiveness - simplified and modernized */
@media (max-width: 768px) {
	.button-container {
		width: 90%;
		max-width: min(90vw, 420px); /* Prevent overflow and set reasonable max */
		margin: 0 auto; /* Center horizontally */
	}

	/* Adjust spacing for mobile */
	.position-wrapper {
		margin-top: max(0.5rem, 2vh); /* Responsive top margin */
		margin-bottom: max(1.5rem, 4vh); /* Responsive bottom margin */
		padding: 0 max(8px, 2vw) max(24px, 5vh); /* Responsive padding */
		max-height: min(calc(100vh - 180px), 550px); /* Better height control for various devices */
		overflow-y: auto; /* Allow vertical scrolling if needed */
		-webkit-overflow-scrolling: touch; /* Smooth scroll on iOS */
	}

	/* Make the visualizer more compact on mobile */
	.visualizer-container {
		display: flex;
		justify-content: center;
		width: 100%;
	}

	/* Ensure minimum width even on very small screens */
	.wrapper-container {
		min-width: min(280px, 95vw); /* Prevent overflow on tiny screens */
		display: flex;
		justify-content: center;
	}
}

/* Even smaller screens */
@media (max-width: 380px) {
	/* Ensure proper spacing on tiny screens */
	.position-wrapper {
		margin-top: 0.5rem;
		margin-bottom: 2rem;
		padding: 0 4px 24px;
		max-height: calc(100vh - 190px); /* More compact on very small screens */
		overflow: hidden;
	}
}
</style>